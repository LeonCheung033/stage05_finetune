{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a34f5b5a",
   "metadata": {},
   "source": [
    "# 0.Preparatiion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f76b1a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install required packages\n",
    "# -q stands for \"quiet\" and suppresses output of the installation process.\n",
    "# -U stands for \"upgrade\" and ensures that the latest version of the package is installed.\n",
    "! pip install -qU peft accelerate datasets einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20fbe83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "from einops import rearrange\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModel, AutoModelForCausalLM\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "dtype = torch.bfloat16 if device != 'cpu' and torch.cuda.is_bf16_supported() else torch.float32\n",
    "print(f'device: {device}\\ndtype: {dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0161400d",
   "metadata": {},
   "source": [
    "# 1. LoRA by custom llama model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58f89e4",
   "metadata": {},
   "source": [
    "## 1.1 declare lora module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f077b90f",
   "metadata": {},
   "source": [
    "create a small model, using llama as example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6ef45024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaModel(\n",
      "  (embed_tokens): Embedding(128, 24)\n",
      "  (layers): ModuleList(\n",
      "    (0-3): 4 x LlamaDecoderLayer(\n",
      "      (self_attn): LlamaAttention(\n",
      "        (q_proj): Linear(in_features=24, out_features=24, bias=False)\n",
      "        (k_proj): Linear(in_features=24, out_features=12, bias=False)\n",
      "        (v_proj): Linear(in_features=24, out_features=12, bias=False)\n",
      "        (o_proj): Linear(in_features=24, out_features=24, bias=False)\n",
      "      )\n",
      "      (mlp): LlamaMLP(\n",
      "        (gate_proj): Linear(in_features=24, out_features=96, bias=False)\n",
      "        (up_proj): Linear(in_features=24, out_features=96, bias=False)\n",
      "        (down_proj): Linear(in_features=96, out_features=24, bias=False)\n",
      "        (act_fn): SiLU()\n",
      "      )\n",
      "      (input_layernorm): LlamaRMSNorm((24,), eps=1e-06)\n",
      "      (post_attention_layernorm): LlamaRMSNorm((24,), eps=1e-06)\n",
      "    )\n",
      "  )\n",
      "  (norm): LlamaRMSNorm((24,), eps=1e-06)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaConfig, LlamaForCausalLM\n",
    "\n",
    "# 创建 LLaMA 模型的配置\n",
    "config = LlamaConfig(\n",
    "    hidden_size=24,\n",
    "    intermediate_size=24 * 4,  # 根据你的公式\n",
    "    num_attention_heads=4,\n",
    "    num_hidden_layers=4,\n",
    "    num_key_value_heads=2,\n",
    "    vocab_size=128\n",
    ")\n",
    "\n",
    "# 使用配置创建模型\n",
    "# raw_model = LlamaForCausalLM(config) # 创建的是带lm_head的模型\n",
    "# 使用 AutoModel 创建模型,创建的是无特定任务头的模型\n",
    "raw_model = AutoModel.from_config(config)\n",
    "\n",
    "# 打印模型结构\n",
    "print(raw_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b456e6d5",
   "metadata": {},
   "source": [
    "then we will create our LoRA class:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74be1747",
   "metadata": {},
   "source": [
    "there is a 'test_model' attribute in the class to control whether lora_B is full zero or not, if true, lora_B is full zero, else lora_B is not zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "111c0bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoraLinear(nn.Module):\n",
    "    def __init__(\n",
    "    self,\n",
    "    base_layer: nn.Linear,\n",
    "    r: int = 8,\n",
    "    alpha: int = 16,\n",
    "    dropout_p: float = 0.0,\n",
    "    test_mode: bool = False,\n",
    "    ):\n",
    "        super(LoraLinear, self).__init__()\n",
    "        self.base_layer = copy.deepcopy(base_layer)\n",
    "        self.r = r\n",
    "        self.alpha = alpha\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "        # 因为轻量化原因，我们只需要使用nn.Parameter来创建两个参数矩阵\n",
    "        # 使用linear的话会包含优化器状态，梯度计算等功能，无需这么多\n",
    "        self.lora_A = nn.Parameter(torch.empty(self.r, self.base_layer.in_features, dtype=self.base_layer.weight.dtype))\n",
    "        self.lora_B = nn.Parameter(torch.empty(self.base_layer.out_features, self.r, dtype=self.base_layer.weight.dtype))\n",
    "        nn.init.normal_(self.lora_A, mean=0.0, std=0.02)\n",
    "        if test_mode:\n",
    "            nn.init.normal_(self.lora_B, mean=0.0, std=0.02)\n",
    "        else:\n",
    "            nn.init.zeros_(self.lora_B)\n",
    "        # frozen the parameters of base layer\n",
    "        for param in self.base_layer.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        scaling = float(self.alpha) / float(self.r)\n",
    "        # linear是一个线性变换操作，y = x @ W^T + b\n",
    "        # x's shape is (batch_size, seq_length, in_features)\n",
    "        # F.linear 期望权重矩阵的形状为 (out_features, in_features)，故lora_A的形状为 (r, in_features)\n",
    "        # output shape is (batch_size, seq_length, r)\n",
    "        lora_adjustment = F.linear(self.dropout(x), self.lora_A)\n",
    "        lora_adjustment = F.linear(lora_adjustment, self.lora_B) \n",
    "        return self.base_layer(x) + lora_adjustment * scaling    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eb1f68f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: embed_tokens, child:Embedding(128, 24)\n",
      "name: layers, child:ModuleList(\n",
      "  (0-3): 4 x LlamaDecoderLayer(\n",
      "    (self_attn): LlamaAttention(\n",
      "      (q_proj): Linear(in_features=24, out_features=24, bias=False)\n",
      "      (k_proj): Linear(in_features=24, out_features=12, bias=False)\n",
      "      (v_proj): Linear(in_features=24, out_features=12, bias=False)\n",
      "      (o_proj): Linear(in_features=24, out_features=24, bias=False)\n",
      "    )\n",
      "    (mlp): LlamaMLP(\n",
      "      (gate_proj): Linear(in_features=24, out_features=96, bias=False)\n",
      "      (up_proj): Linear(in_features=24, out_features=96, bias=False)\n",
      "      (down_proj): Linear(in_features=96, out_features=24, bias=False)\n",
      "      (act_fn): SiLU()\n",
      "    )\n",
      "    (input_layernorm): LlamaRMSNorm((24,), eps=1e-06)\n",
      "    (post_attention_layernorm): LlamaRMSNorm((24,), eps=1e-06)\n",
      "  )\n",
      ")\n",
      "name: norm, child:LlamaRMSNorm((24,), eps=1e-06)\n",
      "name: rotary_emb, child:LlamaRotaryEmbedding()\n"
     ]
    }
   ],
   "source": [
    "for name, child in raw_model.named_children():\n",
    "    print(f\"name: {name}, child:{child}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdec57c",
   "metadata": {},
   "source": [
    "declare the func to replace the original linear layer to lora linear layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c52d75",
   "metadata": {},
   "source": [
    "## 1.2 declare replace_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "485d08e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_linear_with_lora(\n",
    "    module: nn.Module,\n",
    "    r: int = 8,\n",
    "    alpha: int = 16,\n",
    "    dropout_p: float = 0.0,\n",
    "    embed_requires_grad: bool = False,\n",
    "    norm_requires_grad: bool = False,\n",
    "    head_requires_grad: bool = False,\n",
    "    test_mode: bool = False,\n",
    "):\n",
    "    for name, child in module.named_children():\n",
    "        if any(s in name for s in [\"embed\", \"norm\", \"head\"]):\n",
    "            requires_grad = embed_requires_grad if \"embed\" in name \\\n",
    "                else norm_requires_grad if \"norm\" in name \\\n",
    "                else head_requires_grad\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = requires_grad\n",
    "        elif isinstance(child, nn.Linear):\n",
    "            lora_linear = LoraLinear(child, r, alpha, dropout_p, test_mode=test_mode)\n",
    "            # 将模块 module 中名为 name 的子模块替换为新的 LoraLinear 实例\n",
    "            # 该module之后的weight名称为lora_A和lora_B,所以打印的时候会看到是lora_A和lora_B\n",
    "            setattr(module, name, lora_linear)\n",
    "        else:\n",
    "            replace_linear_with_lora(\n",
    "                child,r,alpha,dropout_p,\n",
    "                embed_requires_grad,norm_requires_grad,head_requires_grad\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca9c59d",
   "metadata": {},
   "source": [
    "## 1.3 declare unload and load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7b34f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unload_lora(module: nn.Module, adapter_name: str = 'adapter'):\n",
    "    lora_parameters = {}\n",
    "    def search_lora_linear(module: nn.Module, prefix: List[str]):\n",
    "        for name, child in module.named_children():\n",
    "            new_prefix = prefix + [name]\n",
    "            if isinstance(child, LoraLinear):\n",
    "                lora_parameters['.'.join(new_prefix)] = {\n",
    "                    \"lora_A_weight\": child.lora_A.data.cpu(),\n",
    "                    \"lora_B_weight\": child.lora_B.data.cpu(),\n",
    "                    \"r\": child.r,\n",
    "                    \"alpha\": child.alpha,\n",
    "                    \"dropout_p\": child.dropout.p, # 这里是dropout.p，因为我们这个module的成员变量是dropout，所以这里取dropout.p，没有dropout_p\n",
    "                }\n",
    "                setattr(module, name, child.base_layer)\n",
    "            else:\n",
    "                search_lora_linear(child, new_prefix)\n",
    "    \n",
    "    search_lora_linear(module, [])\n",
    "    # 解冻原模型的所有参数\n",
    "    for name, param in module.named_parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    torch.save(lora_parameters, f\"{adapter_name}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ffaac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lora(module: nn.Module, adapter_name: str = 'adapter'):\n",
    "    lora_parameters = torch.load(f'{adapter_name}.pt')\n",
    "    \n",
    "    for name, lora_params in lora_parameters.items():\n",
    "        # 取出那些需要被替换成lora module的module,别写成named_children。\n",
    "        child = dict(module.named_modules())[name]\n",
    "        if isinstance(child, nn.Linear):\n",
    "            lora_linear = LoraLinear(child, lora_params['r'], lora_params['alpha'], lora_params['dropout_p'] )\n",
    "            lora_linear.lora_A.data = lora_params['lora_A_weight'].to(lora_linear.lora_A.device)\n",
    "            lora_linear.lora_B.data = lora_params['lora_B_weight'].to(lora_linear.lora_B.device)\n",
    "            \n",
    "            parts = name.split(\".\")\n",
    "            obj = module\n",
    "            for part in parts[:-1]:\n",
    "                obj = getattr(obj, part)\n",
    "            setattr(obj, parts[-1], lora_linear)\n",
    "    \n",
    "    for name, param in module.named_parameters():\n",
    "        if any(s in name for s in ['embed', 'norm', 'lm_head']):\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29ab253",
   "metadata": {},
   "source": [
    "## 1.4 test the create of lora_llama "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ce4a3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model: nn.Module):\n",
    "    \"\"\"\n",
    "    打印可训练参数，和 PeftModel 的方法类似\n",
    "    \"\"\"\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    trainable_percentage = 100 * trainable_params / total_params\n",
    "\n",
    "    print(f\"trainable params: {trainable_params:,} || all params: {total_params:,} || trainable%: {trainable_percentage:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "92f22bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 37,848 || all params: 37,848 || trainable%: 100.0000\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(raw_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "193e3e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 16,896 || all params: 54,744 || trainable%: 30.8637\n"
     ]
    }
   ],
   "source": [
    "lora_model = copy.deepcopy(raw_model)\n",
    "replace_linear_with_lora(lora_model)\n",
    "print_trainable_parameters(lora_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9193147e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaModel(\n",
      "  (embed_tokens): Embedding(128, 24)\n",
      "  (layers): ModuleList(\n",
      "    (0-3): 4 x LlamaDecoderLayer(\n",
      "      (self_attn): LlamaAttention(\n",
      "        (q_proj): LoraLinear(\n",
      "          (base_layer): Linear(in_features=24, out_features=24, bias=False)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (k_proj): LoraLinear(\n",
      "          (base_layer): Linear(in_features=24, out_features=12, bias=False)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (v_proj): LoraLinear(\n",
      "          (base_layer): Linear(in_features=24, out_features=12, bias=False)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (o_proj): LoraLinear(\n",
      "          (base_layer): Linear(in_features=24, out_features=24, bias=False)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (mlp): LlamaMLP(\n",
      "        (gate_proj): LoraLinear(\n",
      "          (base_layer): Linear(in_features=24, out_features=96, bias=False)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (up_proj): LoraLinear(\n",
      "          (base_layer): Linear(in_features=24, out_features=96, bias=False)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (down_proj): LoraLinear(\n",
      "          (base_layer): Linear(in_features=96, out_features=24, bias=False)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (act_fn): SiLU()\n",
      "      )\n",
      "      (input_layernorm): LlamaRMSNorm((24,), eps=1e-06)\n",
      "      (post_attention_layernorm): LlamaRMSNorm((24,), eps=1e-06)\n",
      "    )\n",
      "  )\n",
      "  (norm): LlamaRMSNorm((24,), eps=1e-06)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(lora_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bc6bb438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_parameters(model):\n",
    "    print(\"Layer Name & Parameters\")\n",
    "    print(\"-------------------\")\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{name:50} | Requires Grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b15e5da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name & Parameters\n",
      "-------------------\n",
      "embed_tokens.weight                                | Requires Grad: False\n",
      "layers.0.self_attn.q_proj.lora_A                   | Requires Grad: True\n",
      "layers.0.self_attn.q_proj.lora_B                   | Requires Grad: True\n",
      "layers.0.self_attn.q_proj.base_layer.weight        | Requires Grad: False\n",
      "layers.0.self_attn.k_proj.lora_A                   | Requires Grad: True\n",
      "layers.0.self_attn.k_proj.lora_B                   | Requires Grad: True\n",
      "layers.0.self_attn.k_proj.base_layer.weight        | Requires Grad: False\n",
      "layers.0.self_attn.v_proj.lora_A                   | Requires Grad: True\n",
      "layers.0.self_attn.v_proj.lora_B                   | Requires Grad: True\n",
      "layers.0.self_attn.v_proj.base_layer.weight        | Requires Grad: False\n",
      "layers.0.self_attn.o_proj.lora_A                   | Requires Grad: True\n",
      "layers.0.self_attn.o_proj.lora_B                   | Requires Grad: True\n",
      "layers.0.self_attn.o_proj.base_layer.weight        | Requires Grad: False\n",
      "layers.0.mlp.gate_proj.lora_A                      | Requires Grad: True\n",
      "layers.0.mlp.gate_proj.lora_B                      | Requires Grad: True\n",
      "layers.0.mlp.gate_proj.base_layer.weight           | Requires Grad: False\n",
      "layers.0.mlp.up_proj.lora_A                        | Requires Grad: True\n",
      "layers.0.mlp.up_proj.lora_B                        | Requires Grad: True\n",
      "layers.0.mlp.up_proj.base_layer.weight             | Requires Grad: False\n",
      "layers.0.mlp.down_proj.lora_A                      | Requires Grad: True\n",
      "layers.0.mlp.down_proj.lora_B                      | Requires Grad: True\n",
      "layers.0.mlp.down_proj.base_layer.weight           | Requires Grad: False\n",
      "layers.0.input_layernorm.weight                    | Requires Grad: False\n",
      "layers.0.post_attention_layernorm.weight           | Requires Grad: False\n",
      "layers.1.self_attn.q_proj.lora_A                   | Requires Grad: True\n",
      "layers.1.self_attn.q_proj.lora_B                   | Requires Grad: True\n",
      "layers.1.self_attn.q_proj.base_layer.weight        | Requires Grad: False\n",
      "layers.1.self_attn.k_proj.lora_A                   | Requires Grad: True\n",
      "layers.1.self_attn.k_proj.lora_B                   | Requires Grad: True\n",
      "layers.1.self_attn.k_proj.base_layer.weight        | Requires Grad: False\n",
      "layers.1.self_attn.v_proj.lora_A                   | Requires Grad: True\n",
      "layers.1.self_attn.v_proj.lora_B                   | Requires Grad: True\n",
      "layers.1.self_attn.v_proj.base_layer.weight        | Requires Grad: False\n",
      "layers.1.self_attn.o_proj.lora_A                   | Requires Grad: True\n",
      "layers.1.self_attn.o_proj.lora_B                   | Requires Grad: True\n",
      "layers.1.self_attn.o_proj.base_layer.weight        | Requires Grad: False\n",
      "layers.1.mlp.gate_proj.lora_A                      | Requires Grad: True\n",
      "layers.1.mlp.gate_proj.lora_B                      | Requires Grad: True\n",
      "layers.1.mlp.gate_proj.base_layer.weight           | Requires Grad: False\n",
      "layers.1.mlp.up_proj.lora_A                        | Requires Grad: True\n",
      "layers.1.mlp.up_proj.lora_B                        | Requires Grad: True\n",
      "layers.1.mlp.up_proj.base_layer.weight             | Requires Grad: False\n",
      "layers.1.mlp.down_proj.lora_A                      | Requires Grad: True\n",
      "layers.1.mlp.down_proj.lora_B                      | Requires Grad: True\n",
      "layers.1.mlp.down_proj.base_layer.weight           | Requires Grad: False\n",
      "layers.1.input_layernorm.weight                    | Requires Grad: False\n",
      "layers.1.post_attention_layernorm.weight           | Requires Grad: False\n",
      "layers.2.self_attn.q_proj.lora_A                   | Requires Grad: True\n",
      "layers.2.self_attn.q_proj.lora_B                   | Requires Grad: True\n",
      "layers.2.self_attn.q_proj.base_layer.weight        | Requires Grad: False\n",
      "layers.2.self_attn.k_proj.lora_A                   | Requires Grad: True\n",
      "layers.2.self_attn.k_proj.lora_B                   | Requires Grad: True\n",
      "layers.2.self_attn.k_proj.base_layer.weight        | Requires Grad: False\n",
      "layers.2.self_attn.v_proj.lora_A                   | Requires Grad: True\n",
      "layers.2.self_attn.v_proj.lora_B                   | Requires Grad: True\n",
      "layers.2.self_attn.v_proj.base_layer.weight        | Requires Grad: False\n",
      "layers.2.self_attn.o_proj.lora_A                   | Requires Grad: True\n",
      "layers.2.self_attn.o_proj.lora_B                   | Requires Grad: True\n",
      "layers.2.self_attn.o_proj.base_layer.weight        | Requires Grad: False\n",
      "layers.2.mlp.gate_proj.lora_A                      | Requires Grad: True\n",
      "layers.2.mlp.gate_proj.lora_B                      | Requires Grad: True\n",
      "layers.2.mlp.gate_proj.base_layer.weight           | Requires Grad: False\n",
      "layers.2.mlp.up_proj.lora_A                        | Requires Grad: True\n",
      "layers.2.mlp.up_proj.lora_B                        | Requires Grad: True\n",
      "layers.2.mlp.up_proj.base_layer.weight             | Requires Grad: False\n",
      "layers.2.mlp.down_proj.lora_A                      | Requires Grad: True\n",
      "layers.2.mlp.down_proj.lora_B                      | Requires Grad: True\n",
      "layers.2.mlp.down_proj.base_layer.weight           | Requires Grad: False\n",
      "layers.2.input_layernorm.weight                    | Requires Grad: False\n",
      "layers.2.post_attention_layernorm.weight           | Requires Grad: False\n",
      "layers.3.self_attn.q_proj.lora_A                   | Requires Grad: True\n",
      "layers.3.self_attn.q_proj.lora_B                   | Requires Grad: True\n",
      "layers.3.self_attn.q_proj.base_layer.weight        | Requires Grad: False\n",
      "layers.3.self_attn.k_proj.lora_A                   | Requires Grad: True\n",
      "layers.3.self_attn.k_proj.lora_B                   | Requires Grad: True\n",
      "layers.3.self_attn.k_proj.base_layer.weight        | Requires Grad: False\n",
      "layers.3.self_attn.v_proj.lora_A                   | Requires Grad: True\n",
      "layers.3.self_attn.v_proj.lora_B                   | Requires Grad: True\n",
      "layers.3.self_attn.v_proj.base_layer.weight        | Requires Grad: False\n",
      "layers.3.self_attn.o_proj.lora_A                   | Requires Grad: True\n",
      "layers.3.self_attn.o_proj.lora_B                   | Requires Grad: True\n",
      "layers.3.self_attn.o_proj.base_layer.weight        | Requires Grad: False\n",
      "layers.3.mlp.gate_proj.lora_A                      | Requires Grad: True\n",
      "layers.3.mlp.gate_proj.lora_B                      | Requires Grad: True\n",
      "layers.3.mlp.gate_proj.base_layer.weight           | Requires Grad: False\n",
      "layers.3.mlp.up_proj.lora_A                        | Requires Grad: True\n",
      "layers.3.mlp.up_proj.lora_B                        | Requires Grad: True\n",
      "layers.3.mlp.up_proj.base_layer.weight             | Requires Grad: False\n",
      "layers.3.mlp.down_proj.lora_A                      | Requires Grad: True\n",
      "layers.3.mlp.down_proj.lora_B                      | Requires Grad: True\n",
      "layers.3.mlp.down_proj.base_layer.weight           | Requires Grad: False\n",
      "layers.3.input_layernorm.weight                    | Requires Grad: False\n",
      "layers.3.post_attention_layernorm.weight           | Requires Grad: False\n",
      "norm.weight                                        | Requires Grad: False\n"
     ]
    }
   ],
   "source": [
    "print_model_parameters(lora_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79361b7",
   "metadata": {},
   "source": [
    "## 1.5 test the load and unload function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ac4c39b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个测试 tensor\n",
    "bsz = 2\n",
    "seq_len = 8\n",
    "# 生成一个张量，其元素是从 [low, high) 范围内的整数均匀随机采样，size是tensor的形状\n",
    "test_tensor = torch.randint(0, config.vocab_size, (bsz, seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ee430cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model_test = copy.deepcopy(raw_model)\n",
    "replace_linear_with_lora(lora_model_test, test_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "09545a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 37,848 || all params: 37,848 || trainable%: 100.0000\n"
     ]
    }
   ],
   "source": [
    "raw_model.eval()\n",
    "print_trainable_parameters(raw_model)\n",
    "raw_res = raw_model(test_tensor).last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "17b2358f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 24])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_res.shape # [batch_size, seq_len, hidden_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7ddfbe63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 16,896 || all params: 54,744 || trainable%: 30.8637\n"
     ]
    }
   ],
   "source": [
    "lora_model.eval()\n",
    "print_trainable_parameters(lora_model)\n",
    "before_unload_res = lora_model(test_tensor).last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "76675a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "unload_lora(lora_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c5def3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 37,848 || all params: 37,848 || trainable%: 100.0000\n"
     ]
    }
   ],
   "source": [
    "lora_model.eval()\n",
    "print_trainable_parameters(lora_model)\n",
    "before_unload_res = lora_model(test_tensor).last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ac3c372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_lora(lora_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "05ba4aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 16,896 || all params: 54,744 || trainable%: 30.8637\n"
     ]
    }
   ],
   "source": [
    "# 重新装载 lora 后的前向结果\n",
    "\n",
    "lora_model.eval()\n",
    "print_trainable_parameters(lora_model)  # 检查参数和可训练情况\n",
    "load_res = lora_model(test_tensor).last_hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d15dd4c",
   "metadata": {},
   "source": [
    "# 2. lora finetuning by litellama-460M-1T model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6671f2c5",
   "metadata": {},
   "source": [
    "## 2.1 加载模型和分词器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "423fe1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ahxt/LiteLlama-460M-1T'\n",
    "data_name = 'vicgalle/alpaca-gpt4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d0611c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861f9ef936e2465e965b9feb330025cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/252 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93544d0c59d48ebb42f0a5cd77d8d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c40a16513e4094903a8c269a7c6e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7033ccdbdd17460d8c18b917d01be801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d83ffdd098540518cd55d8374ca310a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/364 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70d2d1449874dda9f2a97315d763824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/923M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9635ecd80c343698e74561e452a0f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=dtype).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79581ce",
   "metadata": {},
   "source": [
    "## 2.2 将模型的线性层替换成lora module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "232fef71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,177,920 || all params: 465,863,680 || trainable%: 0.8968\n"
     ]
    }
   ],
   "source": [
    "replace_linear_with_lora(model, r=8, alpha=16, dropout_p=0.0)\n",
    "model.to(device)\n",
    "\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b2d4870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(50304, 1024, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-23): 24 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): LoraLinear(\n",
      "            (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (k_proj): LoraLinear(\n",
      "            (base_layer): Linear(in_features=1024, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (v_proj): LoraLinear(\n",
      "            (base_layer): Linear(in_features=1024, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (o_proj): LoraLinear(\n",
      "            (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): LoraLinear(\n",
      "            (base_layer): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (up_proj): LoraLinear(\n",
      "            (base_layer): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (down_proj): LoraLinear(\n",
      "            (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((1024,), eps=1e-06)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((1024,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((1024,), eps=1e-06)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1024, out_features=50304, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b532cea7",
   "metadata": {},
   "source": [
    "## 2.3 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dad6d7",
   "metadata": {},
   "source": [
    "### 2.3.1 构造数据集类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0b3568",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SFTDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer: AutoTokenizer,\n",
    "        data_path: str,\n",
    "        load_local: bool = False,\n",
    "        max_len: int = 256,\n",
    "        split_len: str = '1%',\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        if load_local:\n",
    "            self.ds = load_dataset('json', data_dir=data_path, split=f'train[:{split_len}]')\n",
    "        else:\n",
    "            self.ds = load_dataset(data_path, split=f'train[:{split_len}]')\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        def process_func(example):\n",
    "            instruction = example['instruction'].strip()\n",
    "            input = example['input'].strip()\n",
    "            output = example['output'].strip()\n",
    "            \n",
    "            instruction_prompt = f\"Human: {instruction}\\n\" + \\\n",
    "                                (f\"{input}\\n\" if len(input) > 0 else \"\") + \\\n",
    "                                    \"Assistant: \"\n",
    "            \n",
    "            output_prompt = f\"{output}\\n\"\n",
    "            \n",
    "            # 截断，最大不超过 max_len\n",
    "            tokenized_instruction = self.tokenizer(instruction_prompt, add_special_tokens=False)['input_ids']\n",
    "            tokenized_output = self.tokenizer(output_prompt, add_special_tokens=False)['input_ids']\n",
    "            # 将会丢弃超出max_len长度的那部分token，存在一定的问题，可能导致masked_attention全是0，然后导致loss为0\n",
    "            tokenized_prompt = (tokenized_instruction + tokenized_output)[:self.max_len]\n",
    "            \n",
    "            # 构造 input_ids, attention_mask, labels\n",
    "            input_ids = tokenized_prompt[:-1]\n",
    "            padding_mask = ([0] * len(tokenized_instruction) + [1] * (len(tokenized_output)))[:self.max_len][1:]\n",
    "            labels = tokenized_prompt[1:]\n",
    "\n",
    "            return {\n",
    "                'input_ids': torch.LongTensor(input_ids),\n",
    "                'attention_mask': torch.LongTensor(padding_mask),\n",
    "                'labels': torch.LongTensor(labels),\n",
    "            }           \n",
    "        self.ds = self.ds.map(\n",
    "            process_func,\n",
    "            batched=False,\n",
    "            remove_columns=self.ds.column_names,\n",
    "            desc='Processing dataset...'\n",
    "        )    \n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    def __getitem__(self, index: int):\n",
    "        return self.ds[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a7ae9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a96b0f07aa6b4ca780fc72cc8b604116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd153e7a47c4729b544baa0487c35e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-6ef3991c06080e14.parquet:   0%|          | 0.00/48.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82221b5e5b644d9780ca0dba5089dc15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/52002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06196667a7ac47f1b8172b61b9fd5998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing dataset...:   0%|          | 0/520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = SFTDataset(tokenizer, data_name, load_local=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fcfccc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n",
      "[20490, 25, 13786, 1115, 9040, 329, 10589, 5448, 13, 198, 48902, 25, 220, 16, 13, 27574, 257, 12974, 290, 48102, 5496, 25, 6889, 1654, 534, 13840, 389, 19889, 286, 257, 4996, 286, 15921, 290, 13701, 11, 10904, 7532, 11, 2187, 21824, 11, 290, 5448, 27997, 13, 770, 5419, 284, 2148, 534, 1767, 351, 262, 6393, 20901, 284, 2163, 379, 663, 1266, 290, 460, 1037, 2948, 10726, 10040, 13, 198, 198, 17, 13, 1985, 496, 287, 3218, 3518, 3842, 25, 32900, 318, 8780, 329, 10941, 1913, 11945, 11, 12749, 11, 290, 21134, 1535, 13, 36223, 329, 379, 1551, 6640, 2431, 286, 10768, 43294, 5517, 393, 5441, 2431, 286, 31543, 5517, 1123, 1285, 13, 198, 198, 18, 13, 3497, 1576, 3993, 25, 18067, 1576, 3081, 3993, 318, 8780, 329, 3518, 290, 5110, 880, 12, 11873, 13, 632, 5419, 284, 16697, 10038, 11, 2987, 10870, 2163, 11, 290, 6971, 5448, 3349, 290, 10900, 2163, 13, 36223, 329, 767, 12, 24, 2250, 286, 3993, 1123, 1755, 13]\n"
     ]
    }
   ],
   "source": [
    "print(len(ds[0]['input_ids']))\n",
    "print(ds[0]['input_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "460c4396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(len(ds[0]['attention_mask']))\n",
    "print(ds[0]['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ae2e979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n",
      "[25, 13786, 1115, 9040, 329, 10589, 5448, 13, 198, 48902, 25, 220, 16, 13, 27574, 257, 12974, 290, 48102, 5496, 25, 6889, 1654, 534, 13840, 389, 19889, 286, 257, 4996, 286, 15921, 290, 13701, 11, 10904, 7532, 11, 2187, 21824, 11, 290, 5448, 27997, 13, 770, 5419, 284, 2148, 534, 1767, 351, 262, 6393, 20901, 284, 2163, 379, 663, 1266, 290, 460, 1037, 2948, 10726, 10040, 13, 198, 198, 17, 13, 1985, 496, 287, 3218, 3518, 3842, 25, 32900, 318, 8780, 329, 10941, 1913, 11945, 11, 12749, 11, 290, 21134, 1535, 13, 36223, 329, 379, 1551, 6640, 2431, 286, 10768, 43294, 5517, 393, 5441, 2431, 286, 31543, 5517, 1123, 1285, 13, 198, 198, 18, 13, 3497, 1576, 3993, 25, 18067, 1576, 3081, 3993, 318, 8780, 329, 3518, 290, 5110, 880, 12, 11873, 13, 632, 5419, 284, 16697, 10038, 11, 2987, 10870, 2163, 11, 290, 6971, 5448, 3349, 290, 10900, 2163, 13, 36223, 329, 767, 12, 24, 2250, 286, 3993, 1123, 1755, 13, 198]\n"
     ]
    }
   ],
   "source": [
    "print(len(ds[0]['labels']))\n",
    "print(ds[0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "795399e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [20490, 25, 13786, 1115, 9040, 329, 10589, 5448, 13, 198, 48902, 25, 220, 16, 13, 27574, 257, 12974, 290, 48102, 5496, 25, 6889, 1654, 534, 13840, 389, 19889, 286, 257, 4996, 286, 15921, 290, 13701, 11, 10904, 7532, 11, 2187, 21824, 11, 290, 5448, 27997, 13, 770, 5419, 284, 2148, 534, 1767, 351, 262, 6393, 20901, 284, 2163, 379, 663, 1266, 290, 460, 1037, 2948, 10726, 10040, 13, 198, 198, 17, 13, 1985, 496, 287, 3218, 3518, 3842, 25, 32900, 318, 8780, 329, 10941, 1913, 11945, 11, 12749, 11, 290, 21134, 1535, 13, 36223, 329, 379, 1551, 6640, 2431, 286, 10768, 43294, 5517, 393, 5441, 2431, 286, 31543, 5517, 1123, 1285, 13, 198, 198, 18, 13, 3497, 1576, 3993, 25, 18067, 1576, 3081, 3993, 318, 8780, 329, 3518, 290, 5110, 880, 12, 11873, 13, 632, 5419, 284, 16697, 10038, 11, 2987, 10870, 2163, 11, 290, 6971, 5448, 3349, 290, 10900, 2163, 13, 36223, 329, 767, 12, 24, 2250, 286, 3993, 1123, 1755, 13], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [25, 13786, 1115, 9040, 329, 10589, 5448, 13, 198, 48902, 25, 220, 16, 13, 27574, 257, 12974, 290, 48102, 5496, 25, 6889, 1654, 534, 13840, 389, 19889, 286, 257, 4996, 286, 15921, 290, 13701, 11, 10904, 7532, 11, 2187, 21824, 11, 290, 5448, 27997, 13, 770, 5419, 284, 2148, 534, 1767, 351, 262, 6393, 20901, 284, 2163, 379, 663, 1266, 290, 460, 1037, 2948, 10726, 10040, 13, 198, 198, 17, 13, 1985, 496, 287, 3218, 3518, 3842, 25, 32900, 318, 8780, 329, 10941, 1913, 11945, 11, 12749, 11, 290, 21134, 1535, 13, 36223, 329, 379, 1551, 6640, 2431, 286, 10768, 43294, 5517, 393, 5441, 2431, 286, 31543, 5517, 1123, 1285, 13, 198, 198, 18, 13, 3497, 1576, 3993, 25, 18067, 1576, 3081, 3993, 318, 8780, 329, 3518, 290, 5110, 880, 12, 11873, 13, 632, 5419, 284, 16697, 10038, 11, 2987, 10870, 2163, 11, 290, 6971, 5448, 3349, 290, 10900, 2163, 13, 36223, 329, 767, 12, 24, 2250, 286, 3993, 1123, 1755, 13, 198]}\n"
     ]
    }
   ],
   "source": [
    "print(ds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d89ad3",
   "metadata": {},
   "source": [
    "### 2.3.2 构造dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f92423",
   "metadata": {},
   "source": [
    "collate_fn函数的作用是将已经分好批的数据处理成符号模型输入格式的一个批次数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1bd9906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch:List, tokenizer):\n",
    "    max_len = max(len(item['input_ids']) for item in batch)\n",
    "    \n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    labels = []\n",
    "    \n",
    "    for item in batch:\n",
    "        input_id = item['input_ids']\n",
    "        item_attention_mask = item['attention_mask']\n",
    "        label = item['labels']\n",
    "        \n",
    "        pad_len = max_len - len(input_id)\n",
    "        \n",
    "        input_ids.append([tokenizer.eos_token_id]*pad_len + input_id)\n",
    "        attention_mask.append([0]*pad_len + item_attention_mask)\n",
    "        labels.append([tokenizer.eos_token_id]*pad_len + label)\n",
    "    \n",
    "    input_ids = torch.LongTensor(input_ids)\n",
    "    attention_mask = torch.LongTensor(attention_mask)\n",
    "    labels = torch.LongTensor(labels)\n",
    "    # 模型需要键分别为'input_ids', 'attention_mask', 'labels'的字典。\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'labels': labels\n",
    "    }\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cf767a",
   "metadata": {},
   "source": [
    "## 2.4 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5afa30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz = 16\n",
    "lr = 1e-3\n",
    "num_epochs = 10\n",
    "logging_steps = 5\n",
    "max_grad_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0341c2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(ds, batch_size=bsz, shuffle=True, collate_fn=lambda batch: collate_fn(batch, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd679e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x329082750>\n"
     ]
    }
   ],
   "source": [
    "print(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "364506a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 255])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d54084b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc3ffd6",
   "metadata": {},
   "source": [
    "下面是参数更新的公式，$g_{lora\\_A\\_new}$是经过梯度裁剪后的梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5faaccb",
   "metadata": {},
   "source": [
    "$$\\text{lora\\_A} \\gets \\text{lora\\_A} - \\text{lr} \\cdot \\text{adam\\_update}(g_{\\text{lora\\_A\\_new}})$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea83320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将模型设置为训练模式，启用 dropout 和 batch norm 等训练特有行为\n",
    "model.train()\n",
    "\n",
    "# 初始化累积损失和步数，用于计算平均损失\n",
    "total_loss = 0\n",
    "total_step = 0\n",
    "\n",
    "# 外层循环：遍历指定的训练轮数（num_epochs）\n",
    "for epoch in range(num_epochs):\n",
    "    # 内层循环：遍历数据加载器（dataloader），每次获取一个批次（batch）\n",
    "    # tqdm 用于显示训练进度条，desc 显示当前 epoch 信息\n",
    "    for step, batch in enumerate(tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "        # 从 batch 中提取 input_ids, attention_mask, labels，并移动到指定设备（CPU/GPU）\n",
    "        input_ids = batch['input_ids'].to(device)  # 输入 token ID，形状 (batch_size, seq_len)\n",
    "        attention_mask = batch['attention_mask'].to(device)  # 注意力掩码，0 表示忽略，1 表示计算损失，形状 (batch_size, seq_len)\n",
    "        labels = batch['labels'].to(device)  # 目标 token ID，形状 (batch_size, seq_len)\n",
    "        \n",
    "        # 清空优化器的梯度缓存，防止梯度累积\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 模型前向传播，输入 input_ids 和 attention_mask，输出包含 logits 和 loss\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        logits = outputs.logits  # 模型输出的预测 logits，形状 (batch_size, seq_len, vocab_size)\n",
    "        \n",
    "        # 使用 einops.rearrange 重塑 logits 和其他张量，便于交叉熵损失计算\n",
    "        # 将 (batch_size, seq_len, vocab_size) 转换为 ((batch_size * seq_len), vocab_size)\n",
    "        rearranged_logits = rearrange(logits, 'bsz seq_len vocab_size -> (bsz seq_len) vocab_size')\n",
    "        # 将 attention_mask 从 (batch_size, seq_len) 转换为 (batch_size * seq_len)\n",
    "        rearranged_attention_mask = rearrange(attention_mask, 'bsz seq_len -> (bsz seq_len)')\n",
    "        # 将 labels 从 (batch_size, seq_len) 转换为 (batch_size * seq_len)\n",
    "        rearranged_labels = rearrange(labels, 'bsz seq_len -> (bsz seq_len)')\n",
    "        \n",
    "        # 计算交叉熵损失，ignore_index=0 表示忽略 attention_mask 为 0 的位置\n",
    "        # reduction='none' 返回每个 token 的损失，而不是平均值\n",
    "        sum_loss = F.cross_entropy(rearranged_logits, rearranged_labels, ignore_index=0, reduction='none')\n",
    "        \n",
    "        # 根据 attention_mask 加权损失，只计算 mask 为 1 的位置的损失\n",
    "        # 总损失 = (逐 token 损失 * mask) 的和 / mask 为 1 的位置数\n",
    "        loss = torch.sum(sum_loss * rearranged_attention_mask) / torch.sum(rearranged_attention_mask)\n",
    "        \n",
    "        # 反向传播，计算梯度\n",
    "        loss.backward()\n",
    "        \n",
    "        # 梯度裁剪，防止梯度爆炸，max_grad_norm 是最大梯度范数\n",
    "        total_norm = nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        \n",
    "        # 优化器更新模型参数（例如 LoRA 参数 lora_A 和 lora_B）\n",
    "        # $$\\text{lora\\_A} \\gets \\text{lora\\_A} - \\text{lr} \\cdot \\text{adam\\_update}(g_{\\text{lora\\_A\\_new}})$$\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 累积损失值（loss.item() 获取标量值）\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # 累积训练步数\n",
    "        total_step += 1\n",
    "        \n",
    "        # 每 logging_steps 步打印一次平均损失和梯度范数\n",
    "        if total_step % logging_steps == 0:\n",
    "            avg_loss = total_loss / total_step  # 计算平均损失\n",
    "            print(f\"Step: {step+1}/{len(dataloader)}, Loss: {avg_loss:.4f}, Grad Norm: {total_norm:.4f}\", flush=True)\n",
    "    \n",
    "    # 每个 epoch 结束后打印平均损失\n",
    "    print(f\"Epoch {epoch+1} finished, Average Loss: {total_loss/total_step:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1b27ae",
   "metadata": {},
   "source": [
    "## 2.5 推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4843d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Give three tips for staying healthy.\\nAssistant: 1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ds[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a28ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    text: str,\n",
    "    max_new_tokens: int = 200,\n",
    "    do_sample: bool = True,\n",
    "    top_k: int = 40,\n",
    "    temperature: float = 0.3,\n",
    "):\n",
    "    instruction_prompt = f\"Human: {text}\\nAssistant: \"\n",
    "    prompt = tokenizer(instruction_prompt, return_tensors='pt', add_special_tokens=False).to(device)\n",
    "    outputs = model.generate(\n",
    "        **prompt,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=do_sample,\n",
    "        top_k=top_k,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c47317",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_text in [\n",
    "    'Give three tips for staying healthy.',\n",
    "    'What are the three primary colors?',\n",
    "    'Describe the structure of an atom.',\n",
    "]:\n",
    "    print('=' * 80)\n",
    "    print(inference(model, tokenizer, test_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_pytorch_0409",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
